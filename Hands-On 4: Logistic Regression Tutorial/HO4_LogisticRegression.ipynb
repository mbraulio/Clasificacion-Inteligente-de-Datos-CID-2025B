{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOuoue5ScGv7G0iwJB2aF7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbraulio/Clasificacion-Inteligente-de-Datos-CID-2025B/blob/main/Hands-On%204%3A%20Logistic%20Regression%20Tutorial/HO4_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands On 4: Logistic Regression**\n",
        "> ## **1.1 Fundamentos de la Técnica**\n",
        ">>La regresión logística es un modelo estadístico y de machine learning supervisado, lo que significa que utiliza datos previamente etiquetados para aprender un patrón y posteriormente clasificar nuevas observaciones.\n",
        "\n",
        ">>Se emplea principalmente en problemas de clasificación binaria (0/1, sí/no, acepta/rechaza). A diferencia de la regresión lineal, cuyo objetivo es predecir valores numéricos continuos, la regresión logística estima la probabilidad de que una observación pertenezca a una de las dos clases. Por esta razón, sus salidas siempre se encuentran en el rango [0,1].\n",
        "\n",
        ">>La probabilidad que genera el modelo se fundamenta en el concepto de odds (razón de probabilidades), definido como la proporción entre la probabilidad de éxito y la probabilidad de fracaso:\n",
        "\n",
        "$$\n",
        "\\text{odds} = \\frac{1 - p}{p}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "> ## **1.2 Modelo Matemático**\n",
        ">> Una combinación lineal pasada por la función sigmoide.\n",
        "$$\n",
        "\\hat{y} = \\frac{1}{1 + e^{-(w_0 + w_1 x_1 + \\cdots + w_n x_n)}}\n",
        "$$\n",
        "\n",
        ">>El modelo aprende una combinación lineal de los atributos de entrada (igual que en el perceptrón) para encontrar la mejor línea de separación entre las clases, conocida como frontera de decisión:\n",
        "\n",
        "$$\n",
        "\\text {z} = {wx + b}\n",
        "$$\n",
        "\n",
        ">>En lugar de aplicar una función escalón como en el perceptrón, la regresión logística utiliza la función sigmoide para transformar esta combinación lineal en una probabilidad suave y continua:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        ">>De este modo, la sigmoide convierte la distancia de cada punto respecto a la frontera en una probabilidad:\n",
        "\n",
        ">>- valores grandes y positivos de $z$ generan probabilidades cercanas a 1.\n",
        "\n",
        ">>- valores grandes y negativos generan probabilidades cercanas a 0.\n",
        "\n",
        ">>- y cuando $z = 0$, la probabilidad es 0.5, indicando el punto exacto de la frontera de decisión.\n",
        "\n",
        ">>La función sigmoide es el elemento central de la regresión logística. Su propósito es transformar la combinación lineal de entrada en un valor comprendido estrictamente entre 0 y 1, interpretado como una probabilidad.\n",
        "\n",
        ">>### **Funcion de perdida: Log-Loss**\n",
        ">> Para entrenar el modelo no basta con calcular probabilidades: es necesario medir qué tan buenas o malas son esas predicciones. La función utilizada para este propósito es la Log-Loss (también llamada entropía cruzada binaria), definida como:\n",
        "\n",
        "$$\n",
        "\\text{LogLoss}(y, \\hat{y}) = -\\left[ y \\, \\ln(\\hat{y}) + (1 - y)\\,\\ln(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        ">>La magnitud de esta pérdida ofrece una interpretación directa sobre la calidad de las predicciones. En términos generales, valores cercanos a 0 indican un excelente desempeño, mientras que valores próximos o superiores a 1 reflejan predicciones deficientes.\n",
        "\n",
        ">>Cuando el modelo asigna una probabilidad alta al evento correcto, la pérdida resultante es muy pequeña. Por ejemplo, si la etiqueta real es 1 y el modelo predice una probabilidad de 0.95, la Log-Loss es aproximadamente 0.05, lo que refleja una predicción precisa y con alta confianza. Por el contrario, si el modelo asigna una probabilidad baja a un evento que sí ocurre (por ejemplo, $\n",
        "\\hat{y} = 0.2$ cuando $y = 1$), la pérdida aumenta significativamente (generalmente por encima de 1) indicando que el modelo se está inclinando hacia la clase incorrecta.\n",
        "\n",
        ">>El caso más severo ocurre cuando el modelo realiza una predicción muy segura pero incorrecta, como asignar $\\hat{y} = 0.01$ cuando la clase real es 1. En estas situaciones, la Log-Loss supera fácilmente valores de 4 o 5, reflejando un error extremo. Esta característica permite que la función penalice con fuerza las predicciones equivocadas y obligue al modelo a ajustar sus parámetros.\n",
        "\n",
        ">> En resumen, la Log-Loss proporciona una medida continua de error donde:\n",
        "\n",
        ">> - 0.0 a 0.2 : predicciones correctas y confiables\n",
        "\n",
        ">> - 0.2 a 0.7 : predicciones moderadamente buenas o inciertas\n",
        "\n",
        ">> - ≈ 0.69 : corresponde a una predicción totalmente incierta (p = 0.5)\n",
        "\n",
        ">> - $> $ 1.0 : predicciones incorrectas\n",
        "\n",
        ">> - $>$ 2.0 : predicciones muy equivocadas y con exceso de confianza\n",
        "\n",
        ">> Finalmente, una vez calculada la pérdida individual de cada observación, todas se promedian para obtener la pérdida total del modelo, la cual se evalúa con los mismos criterios. A continuación, el algoritmo de gradiente descendente ajusta los parámetros $w$ y $b$ con el objetivo de minimizar esta pérdida total y mejorar progresivamente el modelo.\n",
        "\n",
        ">>### **Algoritmo de Gradiente Descendente**\n",
        ">> Es una técnica de optimización que busca minimizar la función de pérdida moviéndose en la dirección donde dicha pérdida disminuye más rápido.\n",
        "\n",
        ">>El gradiente descendente opera sobre la pérdida total promedio (Log-Loss total), ya que esta representa el desempeño global del modelo sobre todos los datos. Aunque la pérdida se calcula individualmente para cada observación, la actualización de los parámetros se basa en el gradiente de la pérdida total, lo que implica que cada dato contribuye a la corrección, pero las decisiones de ajuste se toman considerando el conjunto completo.\n",
        "\n",
        ">>El procedimiento consiste en calcular las derivadas parciales de la pérdida total con respecto a cada parámetro:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L_{\\text{total}}}{\\partial w}\n",
        "\\quad\\text{y}\\quad\n",
        "\\frac{\\partial L_{\\text{total}}}{\\partial b}\n",
        "$$\n",
        "\n",
        ">>Estas derivadas indican la dirección exacta en la que la pérdida aumenta. Para reducirla, los parámetros se actualizan moviéndose en la dirección opuesta:\n",
        "\n",
        "$$\n",
        "w := w - \\eta \\cdot \\frac{\\partial L_{\\text{total}}}{\\partial w}\n",
        "$$\n",
        "\n",
        "$$\n",
        "b := b - \\eta \\cdot \\frac{\\partial L_{\\text{total}}}{\\partial b}\n",
        "$$\n",
        "\n",
        ">>donde:\n",
        "\n",
        ">>η es la tasa de aprendizaje (learning rate), que controla el tamaño del paso realizado en cada actualización.\n",
        "\n",
        ">> Este proceso se repite iterativamente. En cada ciclo, el modelo:\n",
        "\n",
        ">> - Calcula nuevas probabilidades mediante la sigmoide.\n",
        "\n",
        ">> - Evalúa la pérdida total con Log-Loss.\n",
        "\n",
        ">> - Obtiene el gradiente correspondiente.\n",
        "\n",
        ">> Ajusta w y b ligeramente hacia valores que reduzcan la pérdida.\n",
        "\n",
        ">> Con suficientes iteraciones, el modelo converge hacia un conjunto de parámetros que minimiza la pérdida total, resultando en una frontera de decisión más precisa y en probabilidades mejor calibradas.\n",
        "\n",
        ">## **1.3 Descripción de las Librerias**\n",
        "\n",
        ">> ### **Numpy**\n",
        ">> NumPy (Numerical Python) es una librería fundamental de Python diseñada para realizar operaciones matemáticas y computacionales de manera eficiente. Proporciona estructuras de datos de alto rendimiento, especialmente el arreglo multidimensional o ndarray, que permite almacenar y manipular grandes cantidades de datos numéricos de forma compacta y rápida.\n",
        "\n",
        ">> ### **Matplotlib.pyplot**\n",
        ">>Es un módulo de la librería Matplotlib que proporciona una colección de funciones diseñadas para crear gráficos de manera simple y similar a cómo se hace en MATLAB. Es una de las herramientas más utilizadas en Python para visualización de datos, análisis exploratorio y construcción de gráficos científicos.\n",
        "\n",
        ">> ### **Sklearn.model_selection**\n",
        ">> El módulo sklearn.model_selection forma parte de la librería scikit-learn y proporciona herramientas esenciales para dividir, validar y evaluar modelos de machine learning. Su propósito principal es garantizar que los modelos se entrenen y evalúen de forma correcta, evitando sobreajuste y asegurando resultados confiables.\n",
        "\n",
        ">> ### **Sklearn.preprocessing**\n",
        ">> El módulo sklearn.preprocessing de la librería scikit-learn contiene herramientas destinadas a transformar y preparar los datos antes de entrenar un modelo de machine learning. El preprocesamiento es fundamental porque muchos algoritmos requieren que los datos estén en un formato específico o dentro de ciertos rangos para funcionar correctamente.\n",
        "\n",
        ">> ### **Sklearn.linear_model**\n",
        ">> El módulo sklearn.linear_model forma parte de scikit-learn y contiene algoritmos basados en modelos lineales, es decir, métodos que aprenden una combinación lineal de características para hacer predicciones. Estos modelos son ampliamente utilizados en clasificación, regresión y problemas estadísticos por su simplicidad, interpretabilidad y eficiencia.\n",
        "\n",
        ">> ### **Sklearn.metrics**\n",
        ">>El módulo sklearn.metrics de la librería scikit-learn proporciona un conjunto completo de métricas para evaluar el rendimiento de modelos de machine learning. Su objetivo es medir qué tan bien funcionan los modelos en tareas de clasificación, regresión, clustering y otros tipos de predicción.\n",
        "\n",
        "> ## **1.4 Pipeline**\n",
        ">> ### **Preprocesamiento**\n",
        "```python\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "```\n",
        ">> ### **Predicción**\n",
        "```python\n",
        "modelo = LogisticRegression()  # por defecto usa solver 'lbfgs' y log-loss\n",
        "modelo.fit(X_train_scaled, y_train)\n",
        "# Predicción de clases\n",
        "y_pred = modelo.predict(X_test_scaled)\n",
        "y_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
        "```\n",
        "\n",
        ">> ### **Model Evaluation**\n",
        "```python\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Exactitud (accuracy) en test: {acc*100:.2f}%\")\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "> ## 2. Código\n"
      ],
      "metadata": {
        "id": "hdbHuGs-bIQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1. Mismo dataset sintético de dos clases\n",
        "\n",
        "np.random.seed(42)\n",
        "n_muestras = 100\n",
        "\n",
        "X_clase_0 = np.random.randn(n_muestras // 2, 2) + np.array([1, 1])\n",
        "y_clase_0 = np.zeros((n_muestras // 2, ))\n",
        "\n",
        "X_clase_1 = np.random.randn(n_muestras // 2, 2) + np.array([3, 3])\n",
        "y_clase_1 = np.ones((n_muestras // 2, ))\n",
        "\n",
        "X = np.vstack([X_clase_0, X_clase_1])   # (100, 2)\n",
        "y = np.hstack([y_clase_0, y_clase_1])   # (100, )\n",
        "\n",
        "# Mezclamos\n",
        "indices = np.arange(n_muestras)\n",
        "np.random.shuffle(indices)\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# 2. División en entrenamiento y prueba\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Escalado de características (opcional pero recomendado)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 4. Modelo de Regresión Logística con scikit-learn\n",
        "\n",
        "modelo = LogisticRegression()  # por defecto usa solver 'lbfgs' y log-loss\n",
        "modelo.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "# 5. Predicción y evaluación\n",
        "\n",
        "# Predicción de clases\n",
        "y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "# Probabilidades de la clase 1\n",
        "y_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Exactitud (accuracy) en test: {acc*100:.2f}%\")\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhbvqMXChPz8",
        "outputId": "92f5e88a-ca19-4ef0-d459-d0b4ed23c099"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud (accuracy) en test: 93.33%\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[12  1]\n",
            " [ 1 16]]\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.92      0.92        13\n",
            "         1.0       0.94      0.94      0.94        17\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.93      0.93      0.93        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## **3. Referencias**\n",
        "> - Ibm. (2025, 4 junio). Regresión logística. IBM. https://www.ibm.com/mx-es/think/topics/logistic-regression\n",
        "> - ¿Qué es la regresión logística? - Explicación del modelo de regresión logística - AWS. (s. f.). Amazon Web Services, Inc. https://aws.amazon.com/es/what-is/logistic-regression/\n",
        "> - Navlani, A. (s. f.). Comprender la regresión logística en el tutorial de Python. Datacamp. https://www.datacamp.com/es/tutorial/understanding-logistic-regression-python\n",
        ""
      ],
      "metadata": {
        "id": "pOjR4r7BhzgH"
      }
    }
  ]
}