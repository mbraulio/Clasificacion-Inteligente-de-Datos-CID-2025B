{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbraulio/Clasificacion-Inteligente-de-Datos-CID-2025B/blob/main/Hands-On%201%20%3A%20Perceptron%20Tutorial/HO1_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-on 1: Perceptron Notebook (Tutorial)**\n"
      ],
      "metadata": {
        "id": "xDBOtAafuiJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.1 Fundamentos de la t√©cnica.**\n",
        "\n",
        "El Perceptr√≥n es el modelo de neurona artificial m√°s simple y el primer algoritmo de aprendizaje supervisado que se desarroll√≥ para clasificaci√≥n binaria.\n",
        "Fue propuesto en 1958 por Frank Rosenblatt, y representa el origen de lo que hoy conocemos como redes neuronales.\n",
        "\n",
        "Sus componentes principales se basan en entradas, pesos, sesgo y la funci√≥n de activaci√≥n; Las entradas,  son las variables o caracter√≠sticas del problema (por ejemplo: edad, horas de estudio, temperatura, etc.); Los pesos, son coeficientes que indican la importancia de cada entrada en la decisi√≥n; El sesgo (bias), permite ajustar la posici√≥n de la frontera, act√∫a como un desplazamiento; Y la funci√≥n de activaci√≥n, decide si el perceptr√≥n ‚Äúse activa‚Äù (1) o ‚Äúno se activa‚Äù (0).\n",
        "\n",
        "Su proceso de entrenamiento se define por las siguientes etapas:\n",
        "1. **Inicializaci√≥n:**\n",
        "Pesos y bias se establecen en valores peque√±os o aleatorios.\n",
        "\n",
        "2. **C√°lculo de salida:**\n",
        "Se calcula la salida del perceptr√≥n para cada patr√≥n de entrenamiento.\n",
        "\n",
        "3. **Comparaci√≥n:**\n",
        "Se mide la diferencia entre la salida real y la esperada.\n",
        "\n",
        "4. **Actualizaci√≥n:**\n",
        "Se ajustan los pesos seg√∫n la regla de aprendizaje.\n",
        "\n",
        "5. **Iteraci√≥n:**\n",
        "Se repite el proceso durante varias √©pocas (pasadas completas al conjunto de datos).\n",
        "\n",
        "6. **Convergencia:**\n",
        "Cuando todos los patrones se clasifican correctamente o el cambio en los pesos es muy peque√±o, se detiene.\n",
        "\n",
        "Solo funciona correctamente con datos linealmente separables (como AND, OR, NOT).\n",
        "\n",
        "+ No puede resolver problemas no lineales, como XOR.\n",
        "\n",
        "+ Es sensible a la elecci√≥n de la tasa de aprendizaje.\n",
        "\n",
        "+ Puede tardar en converger o no hacerlo si los datos est√°n mal distribuidos.\n",
        "\n",
        "#**1.2  Modelo Matem√°tico del Perceptr√≥n.**\n",
        "\n",
        "El perceptr√≥n busca aprender una frontera de decisi√≥n lineal que separe dos clases (por ejemplo, 0 y 1).\n",
        "Esa frontera es una recta (en 2D) o un plano (en 3D o m√°s dimensiones).\n",
        "\n",
        "Matem√°ticamente, el perceptr√≥n calcula una combinaci√≥n lineal de las entradas:\n",
        "$$z = w_0 + w_1x_1 + w_2x_2 + \\ldots + w_nx_n$$\n",
        "Donde:\n",
        "\n",
        "$z =$ combinaci√≥n lineal (resultado antes de aplicar la funci√≥n de activaci√≥n).\n",
        "\n",
        "$w_0 =$ sesgo o bias.\n",
        "\n",
        "$x_1, x_2 =$ entradas.\n",
        "\n",
        "$w_1, w_2 =$ pesos asociados a esas entradas.\n",
        "\n",
        "Y luego se aplica la funci√≥n de activaci√≥n:\n",
        "$$\n",
        "y = f(z) =\n",
        "\\begin{cases}\n",
        "1, & \\text{si } z > 0 \\\\\n",
        "0, & \\text{si } z \\le 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Si el resultado es 1, el perceptr√≥n ‚Äúactiva‚Äù la salida;\n",
        "si es 0, la ‚Äúdesactiva‚Äù.\n",
        "\n",
        "\n",
        "El perceptr√≥n aprende ajustando sus pesos seg√∫n los errores que comete durante el entrenamiento.\n",
        "\n",
        "1. Se inicia con pesos aleatorios o en cero.\n",
        "\n",
        "2. Para cada ejemplo $(ùë•,ùë°)$:\n",
        "\n",
        "   + Calcula la salida $y=f(w‚ãÖx)$\n",
        "\n",
        "   + Compara con la salida deseada $t$\n",
        "\n",
        "   + Si se equivoc√≥, actualiza los pesos:\n",
        "\n",
        "$$w_i = w_i + Œ∑ (t-y)x_i$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "$Œ∑ =$ tasa de aprendizaje (learning rate).\n",
        "\n",
        "$t =$ salida esperada (target).\n",
        "\n",
        "$y =$ salida predicha.\n",
        "\n",
        "$x_i =$ entrada correspondiente.\n",
        "\n",
        "Este ajuste mueve la frontera de decisi√≥n ligeramente hacia la direcci√≥n correcta.\n",
        "\n",
        "\n",
        "#**1.3  Descripci√≥n de la librer√≠a, clases, funciones (python) empleadas en programar el Perceptr√≥n**\n",
        "\n",
        "**sklearn.linear_model import Perceptron**\n",
        "\n",
        "Esta clase implementa el Perceptr√≥n de Rosenblatt (el original), es decir, una neurona artificial que:\n",
        "\n",
        "+ ajusta sus pesos y bias,\n",
        "\n",
        "+ utiliza la regla de aprendizaje del perceptr√≥n,\n",
        "\n",
        "+ y clasifica datos linealmente separables.\n",
        "\n",
        "**sklearn.metrics import accuracy_score**\n",
        "\n",
        "+ Compara las etiquetas reales (verdaderas) con las predichas por el modelo\n",
        "\n",
        "+ Y calcula la propocion de aciertos de la siguiente manera:\n",
        "\n",
        "$$\\textit {Accuracy} = \\frac{\\text{n√∫mero de predicciones correctas}}{\\text{n√∫mero total de ejemplos}}$$\n",
        "\n",
        "**Numpy as np**\n",
        "Librer√≠a fundamental de Python para el c√°lculo num√©rico y cient√≠fico que nos permite implementar el uso de arreglos.\n",
        "\n",
        "**Perceptron(max_iter=1000, eta0=1.0, random_state=0)**\n",
        "\n",
        "Donde:\n",
        "\n",
        "+ max_iter=1000 : n√∫mero m√°ximo de iteraciones (√©pocas) para entrenar.\n",
        "\n",
        "+ eta0=1.0 : tasa de aprendizaje (qu√© tanto cambian los pesos en cada error).\n",
        "\n",
        "+ random_state=0 : asegura resultados reproducibles (para que no cambie cada vez que lo ejecutes).\n",
        "\n",
        "+ Repite hasta que no haya errores o se alcance el n√∫mero m√°ximo de iteraciones.\n",
        "\n",
        "**print()**\n",
        "\n",
        "Imprime los resultados en consola.\n",
        "\n",
        "#**1.4. Pipeline  (una subsecci√≥n en el notebook por cada una las siguientes etapas):**\n",
        "\n",
        "+ Feature Engineering (... describir las variables (se√±ales i/o) por emplear)\n",
        "\n",
        "**Variables de entrada y salida**\n",
        "\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "\n",
        "y = np.array([0,1,1,1])\n",
        "\n",
        "Donde: X contiene todos los pares posibles de 0 y 1 como en una compuerta l√≥gica. Por otro lado Y contiene los resultados esperados del operador OR (0 unicamente si ambos pares son 0, y 1 si minimo uno de los dos es 1).\n",
        "\n",
        "\n",
        "+ **Modelo Selection (... describir las razones formales del por qu√© emplear un clasificador lineal)**\n",
        "\n",
        "El clasificador lineal, como el Perceptr√≥n, se utiliza porque ofrece una soluci√≥n simple, eficiente e interpretativa para problemas de clasificaci√≥n donde las clases pueden separarse mediante una frontera recta o un plano.\n",
        "\n",
        "Su funcionamiento se basa en una combinaci√≥n lineal de las variables de entrada ponderadas por coeficientes (pesos), lo que genera una funci√≥n de decisi√≥n lineal del tipo:\n",
        "\n",
        "$$ùë§_0+ùë§_1ùë•_1+ùë§_2 ùë•_2+‚Ä¶+ùë§_ùëõ ùë•_ùëõ = 0 $$\n",
        "\n",
        "\n",
        "Esta simplicidad permite representar el proceso de clasificaci√≥n de forma geom√©trica y anal√≠tica, garantizando convergencia cuando los datos son linealmente separables, seg√∫n el teorema del perceptr√≥n.\n",
        "\n",
        "A nivel computacional, es un modelo ligero y r√°pido de entrenar, ya que solo requiere operaciones b√°sicas, lo que lo hace ideal para conjuntos de datos grandes o para usarse como modelo base de comparaci√≥n.\n",
        "\n",
        "Adem√°s, sus par√°metros son f√°cilmente interpretables: los pesos indican la importancia de cada caracter√≠stica y el sesgo (bias) ajusta el desplazamiento de la frontera de decisi√≥n.\n",
        "\n",
        "Los clasificadores lineales tienen un valor conceptual fundamental, ya que constituyen la base te√≥rica de modelos m√°s avanzados como la regresi√≥n log√≠stica, las m√°quinas de soporte vectorial (SVM) y las redes neuronales multicapa.\n",
        "\n",
        "En conjunto, se emplean porque combinan solidez te√≥rica, eficiencia pr√°ctica e interpretabilidad, ofreciendo una representaci√≥n clara del proceso de decisi√≥n y un punto de partida esencial para el aprendizaje autom√°tico moderno.\n",
        "\n",
        "+ **Model Training (... l√≠neas de c√≥digo respectivas para entrenar al perceptr√≥n (fit)).**\n",
        "\n",
        "**model.fit(X, y)**\n",
        "\n",
        "Aqu√≠ el modelo:\n",
        "\n",
        "+ Calcula salidas.\n",
        "\n",
        "+ Compara con las esperadas.\n",
        "\n",
        "+ Ajusta los pesos con la regla:\n",
        "\n",
        "$$w_i = w_i + Œ∑ (t-y)x_i$$\n",
        "\n",
        "+ Prediction (... crear una funci√≥n para probar que cada patr√≥n de entrada es clasificado de manera correcta).\n",
        "\n",
        "```python\n",
        "def probar_patrones(modelo, X, y_verdad):\n",
        "    print(\"Prueba de patrones:\\n\")\n",
        "    todos_bien = True #bandera que se√±ala si el modelo acert√≥ todos los casos.\n",
        "    \n",
        "    for x, t in zip(X, y_verdad): #une las entradas con sus respectivas salidas\n",
        "        y_pred = modelo.predict([x])[0]   # [x] porque predict espera 2D y [0] ya que predict nos devuelve un array por lo tanto solo queremos el valor para compararlo\n",
        "        correcto = (y_pred == t) #al comparar el valor predecido con el valor real obtenderemos true o false  \n",
        "        if not correcto:\n",
        "            todos_bien = False\n",
        "        \n",
        "        print(f\"Entrada: {x}  ‚Üí  Esperado: {t}  |  Predicho: {y_pred}  |  Correcto: {correcto}\")\n",
        "    \n",
        "    if todos_bien:\n",
        "        print(\"\\n Todos los patrones fueron clasificados correctamente.\")\n",
        "    else:\n",
        "        print(\"\\n Hay patrones mal clasificados.\")\n",
        "```\n",
        "\n",
        "\n",
        "+ **Model Evaluation (... l√≠neas de c√≥digo fuente para calcula la M√©trica Accuracy con una breve explicaci√≥n de los resultados).**\n",
        "```python\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(f\"Exactitud (Accuracy): {accuracy*100:.2f}%\")\n",
        "```\n",
        "El porcentaje sera reflejo del valor de accuracy, si la metrica es del 100% significa que el perceptron clasific√≥ correctamente todos los patrones de entrada, es decir, que las predicciones coincidieron con las salidas reales en todos los casos.\n",
        "\n",
        "#**2.0. Cerciorarse de que el notebook se puedan interpretar y ejecutar, sin errores, en Jupyter y/o Google Colab.**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "#Entradas y salidas\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([0,1,1,1])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model = Perceptron(max_iter=1000, eta0=1.0, random_state=0)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predicciones\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Funci√≥n para comprobar predicciones\n",
        "\n",
        "def probar_patrones(modelo, X, y_verdad):\n",
        "    print(\"\\nPrueba de patrones:\\n\")\n",
        "     todos_bien = True #bandera que indica si el modelo acert√≥ todos los casos.\n",
        "    \n",
        "    for x, t in zip(X, y_verdad):\n",
        "        y_pred = modelo.predict([x])[0]  # [x] porque predict espera 2D y [0] ya que predict nos devuelve un array por lo tanto solo queremos el valor para compararlo con y_pred\n",
        "        correcto = (y_pred == t)\n",
        "        if not correcto:\n",
        "            todos_bien = False\n",
        "        \n",
        "        print(f\"Entrada: {x}  ‚Üí  Esperado: {t}  |  Predicho: {y_pred}  |  Correcto: {correcto}\")\n",
        "    \n",
        "    if todos_bien:\n",
        "        print(\"\\n Todos los patrones fueron clasificados correctamente.\")\n",
        "    else:\n",
        "        print(\"\\n  Hay patrones mal clasificados.\")\n",
        "\n",
        "\n",
        "# Prueba de clasificaci√≥n patr√≥n por patr√≥n\n",
        "probar_patrones(model, X, y)\n",
        "\n",
        "# Precision\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "\n",
        "print(\"Salidas esperadas:\", y)\n",
        "print(\"Salidas predichas:\", y_pred)\n",
        "print(f\"Exactitud (Accuracy): {accuracy*100:.2f}%\")\n",
        "\n",
        "```\n",
        "\n",
        "#**3. Referencias bibliogr√°ficas.**\n",
        "* Daniel. (2023, October 30). Perceptr√≥n: ¬øqu√© es y para qu√© sirve? DataScientest. https://datascientest.com/es/perceptron-que-es-y-para-que-sirve\n",
        "* Alex Hay | Computing Logic Funcitons using Perceptrons. (n.d.). https://alexanderhay2020.github.io/blog/2019/perceptrons/\n",
        "* NeuralNinja. (2023, 26 julio). Perceptron Learning Algorithm: Feedforward and Weight Update. Medium. https://arafique906.medium.com/perceptron-learning-algorithm-feedforward-and-weight-update-e2ba1a9bca12\n"
      ],
      "metadata": {
        "id": "VggwWbtwzEsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Entradas y salidas\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([0,1,1,1])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model = Perceptron(max_iter=1000, eta0=1.0, random_state=0)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predicciones\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Funci√≥n para comprobar predicciones\n",
        "\n",
        "def probar_patrones(modelo, X, y_verdad):\n",
        "    print(\"\\nPrueba de patrones:\\n\")\n",
        "    todos_bien = True #bandera que indica si el modelo acert√≥ todos los casos.\n",
        "\n",
        "    for x, t in zip(X, y_verdad):\n",
        "        y_pred = modelo.predict([x])[0]  # [x] porque predict espera 2D y [0] ya que predict nos devuelve un array por lo tanto solo queremos el valor para compararlo con y_pred\n",
        "        correcto = (y_pred == t)\n",
        "        if not correcto:\n",
        "            todos_bien = False\n",
        "\n",
        "        print(f\"Entrada: {x}  ‚Üí  Esperado: {t}  |  Predicho: {y_pred}  |  Correcto: {correcto}\")\n",
        "\n",
        "    if todos_bien:\n",
        "        print(\"\\n Todos los patrones fueron clasificados correctamente.\")\n",
        "    else:\n",
        "        print(\"\\n  Hay patrones mal clasificados.\")\n",
        "\n",
        "\n",
        "# Prueba de clasificaci√≥n patr√≥n por patr√≥n\n",
        "probar_patrones(model, X, y)\n",
        "\n",
        "# Precision\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "\n",
        "print(\"Salidas esperadas:\", y)\n",
        "print(\"Salidas predichas:\", y_pred)\n",
        "print(f\"Exactitud (Accuracy): {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_HRtowdeGl_",
        "outputId": "8bbe4bb3-dd91-4461-ca4b-726d2396afbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prueba de patrones:\n",
            "\n",
            "Entrada: [0 0]  ‚Üí  Esperado: 0  |  Predicho: 0  |  Correcto: True\n",
            "Entrada: [0 1]  ‚Üí  Esperado: 1  |  Predicho: 1  |  Correcto: True\n",
            "Entrada: [1 0]  ‚Üí  Esperado: 1  |  Predicho: 1  |  Correcto: True\n",
            "Entrada: [1 1]  ‚Üí  Esperado: 1  |  Predicho: 1  |  Correcto: True\n",
            "\n",
            " Todos los patrones fueron clasificados correctamente.\n",
            "Salidas esperadas: [0 1 1 1]\n",
            "Salidas predichas: [0 1 1 1]\n",
            "Exactitud (Accuracy): 100.00%\n"
          ]
        }
      ]
    }
  ]
}